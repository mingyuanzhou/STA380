<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>STA 380 by mingyuanzhou</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>STA 380</h1>
        <p>Bayesian Methods for Machine Learning (Spring 2018)</p>

        <p class="view"><a href="https://github.com/mingyuanzhou/STA380">View the Project on GitHub <small>mingyuanzhou/STA380</small></a></p>


        <ul>
          <li><a href="https://github.com/mingyuanzhou/STA380/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/mingyuanzhou/STA380/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/mingyuanzhou/STA380">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        
        <h3>Basic Information</h3>

<p>
  <ul>
<li><b>Instructor:</b> Mingyuan Zhou, Ph.D., Assistant Professor of Statistics <br> 
<li><b>Office:</b> CBA 6.458 (Six floor, on the east side of the building that faces the entrance of Gregory Gym) </li>
<li><b>Email:</b> <a href="mailto:mingyuan.zhou@mccombs.utexas.edu">mingyuan.zhou@mccombs.utexas.edu</a> 
<li><b>Phone:</b> 512-232-6763
<li><b>Website:</b> 
<a style=" color: blue;" href="http://mingyuanzhou.github.io/">http://mingyuanzhou.github.io/</a></li>
<li><b>Office Hours:</b> Thursday 4:00-5:30 PM. Welcome to come by my office at other times as well. </li>
<li><b>Class time:</b> Thursday 1:00 - 4:00 PM</li>	  
<li><b>Classroom:</b> CBA 6.420 (note the room change to accomodate more students; the classroom is located at the southwest corner of CBA six floor) </li>		   
<!-- <li><b>Syllabus:</b> TBA	-->
<!--<li><b>Teaching Assistant:</b> 
			<ul>
			<li>Quan Zhang, <a href="mailto:quan.zhang@mccombs.utexas.edu">quan.zhang@mccombs.utexas.edu</a>, IROM PhD Student, Office Hours: Tuesday, 2:30-4:00 PM, CBA 4.304A (TA Space C) </li>	
			</ul>
<li><b>Midterm Exam #1:</b> PHR 2.110, 7:00-9:30 pm, Wednesday, 10/11/2017 </li>
<li><b>Midterm Exam #2:</b> PHR 2.110, 7:00-9:30 pm, Wednesday, 11/15/2017 </li>
<li><b>Final Exam:</b> Location TBD, Time TBD, Date TBD</li>
<li><b>Makeup Final Exam:</b> Location TBD, Time TBD, Date TBD</li> </li>			
</ul> --!>
  
<h3>Syllabus</h3>
<p>
<ul>
<a style=" color: blue;" href="notes/syllabus_STA380_Spring2018_ZHOU.pdf">syllabus_STA380_Spring2018_ZHOU.pdf</a> 
</ul>
</p>

<h3>Reading materials</h3>
<p> 
<ul>
<li>Christopher Bishop, Pattern Recognition and Machine Learning
</li>
<li>
Kervin Murphy, Machine Learning: a Probabilistic Perspective
</li>
<li>
Ian Goodfellow, Yoshua Bengio, and Aaron Courville, Deep Learning
</li>
</ul>
<ul>

<li> Lecture 1: Probability, Likelihood, Prior, and Posterior
		<ul>
		    <li> C. Bishop, Chapters 1.2, 1.6, 2.1-2.4
		    </li>
		    <li>K. Murphy, Chapter 2
			</li>
			
				
		</ul>
</li>

<li> Lecture 2: Markov Chain Monte Carlo
		<ul>
		   <li> C. Bishop, Chapters 11.2-11.4
		   </li>
		   <li>K. Murphy, Chapters 23.1-23.4, 24
		   </li>
				
		</ul>
</li>

<li> Lecture 3: Variational Inference, Linear Regression
		<ul>
		   <li> C. Bishop, Chapters 10.1-10.6, 3.1-3.3
		   </li>
		   <li>K. Murphy, Chapters 21, 7
		   </li>
		  <li>
	    		<a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf"> D. Blei, Variational Inference</a>
		   </li>
 		  <li>
	    		<a href="https://arxiv.org/abs/1601.00670"> Blei, Kucukelbir, & McAuliffe,  Variational Inference: A Review for Statisticians</a>
		   </li>
			<li>
		   <a href="https://arxiv.org/abs/1301.3838">Bishop & Tipping, Variational Relevance Vector Machines</a>
		   </li>
		<li>
		   <a href="https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf">K. Murphy, Conjugate Bayesian Analysis of the Gaussian Distribution</a>
		   </li>
			


		
		</ul>
</li>

<li> Lecture 4: Sparse Regression, Classification, Discrete Choice Analysis
		<ul>
		   <li> C. Bishop, Chapters 4.3-4.5, 7.2
		   </li>
		   <li> K. Murphy, Chapters 8, 9.4
		   </li>
		   <li>
		   <a href="http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf">M. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine</a>
		   </li>
		   <li>
		   <a href="http://www.stat.ufl.edu/archived/casella/Papers/Lasso.pdf">Park and Casella, The Bayesian Lasso</a>
		   </li>
<li>
<a href="https://projecteuclid.org/download/pdf_1/euclid.ba/1339611936">Polson & Scott, Data Augmentation for Support Vector
Machines</a>
</li>
<li>
<a href="https://arxiv.org/abs/1205.0310">Polson, Scott, & Windle, Bayesian Inference for Logistic Models Using Polya-Gamma Latent Variables</a>
</li>


		   <li>
 		   <a href="https://eml.berkeley.edu/books/train1201.pdf">K. Train, Discrete Choice Methods with Simulation</a>
		   </li>
		</ul>
</li>


<li> Lecture 5 & 6: Continuous Latent Variable Models, Bayesian Dicitonary Learning and Sparse Coding
	<ul>
		   <li> C. Bishop, Chapter 12
		   </li>
		   <li> K. Murphy, Chapters 12, 13
		   </li>
			<li>
			Goodfellow, Bengio, & Courville, Chapter 13
			</li>
<li> <a href="http://www.di.ens.fr/~fbach/courses/fall2010/Bishop_Tipping_1999_Probabilistic_PCA.pdf">Tipping & Bishop, Probabilistic Principal Components Analysis</a>
</li>

<li> <a href="https://www.cs.toronto.edu/~amnih/papers/bpmf.pdf">Salakhutdinov & Mnih, Bayesian Probabilistic Matrix Factorization using MCMC
</a>
</li>


<li> <a href="http://sites.fas.harvard.edu/~cs278/papers/ksvd.pdf">Aharon, Elad, & Bruckstein, K-SVD: An Algorithm for Designing Overcomplete
Dictionaries for Sparse Representation</a>
</li>
<li> <a href="http://www.egr.msu.edu/~aviyente/elad06.pdf"> Elad & Aharon, Image Denoising Via Sparse and Redundant
Representations Over Learned Dictionaries</a>
</li>

<li>
<a href="https://papers.nips.cc/paper/3851-non-parametric-bayesian-dictionary-learning-for-sparse-image-representations">Zhou et al., Non-parametric Bayesian Dictionary Learning for Sparse Image Representations
</a>
</li>

<li>
<a href="https://dukespace.lib.duke.edu/dspace/bitstream/handle/10161/7204/Zhou_duke_0066D_11883.pdf?sequence=1">Chatper 3 of M. Zhou, Nonparametric Bayesian Dictionary Learning and
Count and Mixture Modeling
</a>
</li>
			

	</ul>

</li>



<li> Lecture 7 & 8: Discrete Data Analysis, Discrete Latent Variable Models, Topic Models, Mixed-Membership Models, Poisson Factor Analysis
	<ul>
		   <li> K. Murphy, Chapters 3, 27
		   </li>

<li> <a href="http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf">Blei, Ng, & Jordan, Latent Dirichlet Allocation
</a>
</li>

<li> <a href="http://www.jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf">Hoffman, Blei, Wang, & Paisley, Stochastic Variational Inference
</a>
</li>

<li> <a href="http://psiexp.ss.uci.edu/research/papers/sciencetopics.pdf">Griffiths & Steyvers, Finding Scientific Topics
</a>
</li>

<li> <a href="https://mingyuanzhou.github.io/Papers/AISTATS2012_NegBinoBeta_PFA_v19.pdf">Zhou, Hannah, Dunson, & Carin, Beta-Negative Binomial Process and Poisson Factor Analysis
</a>
</li>


<li> <a href="https://mingyuanzhou.github.io/Papers/Mingyuan_PAMI_9.pdf">Zhou & Carin, Negative Binomial Process Count and Mixture Modeling
</a>
</li>

<li> <a href="http://mingyuanzhou.github.io/Papers/NBP_VectorMatrix_Journal_revise3_ArXiv.pdf">Zhou & Scott, Priors for Random Count Matrices Derived from a
Family of Negative Binomial Processes
</a>
</li>

		

	</ul>

</li>



<li> Lecture 9: Bayesian Models for Network Analysis, Stochastic Blockmodel, Edge
Partition Model, Community Detection and Link Prediction
	<ul>
		   <li> K. Murphy, Chapters 27.5-27.6
		   </li>

 <li> <a href="https://arxiv.org/pdf/cond-mat/0308217.pdf">Newman & Girvan, Finding and Evaluating Community Structure in Networks
</a>
</li> 

<li> <a href="https://arxiv.org/pdf/0906.0612.pdf">S. Fortunato, Community Detection in Graphs
</a>
</li>

<li> <a href="https://people.eecs.berkeley.edu/~jordan/sail/readings/nowicki-snijders.pdf">Nowicki & Snijders, Estimation and Prediction for Stochastic Blockstructures
</a>
</li>


<li> <a href="http://web.mit.edu/cocosci/Papers/Kemp-etal-AAAI06.pdf">Kemp, Tenenbaum, Griffiths, Yamada,
& Ueda. Learning Systems of Concepts with an Infinite Relational Model
</a>
</li>

<li> <a href="http://jmlr.csail.mit.edu/papers/volume9/airoldi08a/airoldi08a.pdf">Airoldi, Blei, Fienberg, & Xing, Mixed Membership Stochastic Blockmodels
</a>
</li>

<li> <a href="https://papers.nips.cc/paper/3294-modeling-homophily-and-stochastic-equivalence-in-symmetric-relational-data.pdf">P. Hoff, Modeling Homophily and Stochastic Equivalence in
Symmetric Relational Data
</a>
</li>

<li> <a href="http://ai.stanford.edu/~tadayuki/papers/miller-griffiths-jordan-nips09.pdf">Miller, Griffiths, & Jordan, Nonparametric Latent Feature Models
for Link Prediction
</a>
</li>

<li> <a href="https://pdfs.semanticscholar.org/633e/45dcdd316bcf3cb548882c78665cb6235992.pdf">Schmidt & Mørup, Nonparametric Bayesian Modeling of Complex Networks: An Introduction
</a>
</li>

<li> <a href="https://www-cs.stanford.edu/~jure/pubs/agmfit-icdm12.pdf">Yang & Leskovec, Community-Affiliation Graph Model for Overlapping Network Community Detection
</a>
</li>


<li> <a href="http://mingyuanzhou.github.io/Papers/EPM_AISTATS2015_v8_1.pdf">M. Zhou, Infinite Edge Partition Models for Overlapping
Community Detection and Link Prediction</a>
</li>

	</ul>

</li>




<li> Lecture 10 & 11: Bayesian Nonparametrics, Exchangeable Random Partitions, Completely Random Measures, Poisson Processes, Dirichlet Process, Chinese Restaurant Process, Gamma Process, Beta Process, Indian Buffet Process, Gamma/Beta-Negative Binomial Process
	<ul>
		  

<li> <a href="https://books.google.com/books/about/Poisson_Processes.html?id=VEiM-OtwDHkC">J.F.C. Kingman, Poisson Processes
</a>
</li> 


 <li> <a href="https://people.eecs.berkeley.edu/~jordan/papers/hdp.pdf">Teh, Jordan, Beal, & Blei, Hierarchical Dirichlet Processes
</a>
</li> 

 <li> <a href="http://people.ee.duke.edu/~lcarin/thibaux-jordan-aistats07.pdf">Thibaux & Jordan, Hierarchical Beta Processes and the Indian Buffet Process
</a>
</li> 

 <li> <a href="https://cocosci.berkeley.edu/tom/papers/indianbuffet.pdf">Griffiths & Ghahramani, The Indian Buffet Process: An Introduction and Review
</a>
</li>

<li> <a href="http://www.carloalberto.org/assets/working-papers/no.129.pdf">Lijoi & Prunster, Models Beyond the Dirichlet Process
</a>
</li>

<li>
<a href="https://papers.nips.cc/paper/3851-non-parametric-bayesian-dictionary-learning-for-sparse-image-representations">Zhou et al., Non-parametric Bayesian Dictionary Learning for Sparse Image Representations
</a>
</li>

 <li> <a href="http://mingyuanzhou.github.io/Papers/dEPPF_v18.pdf">Zhou, Favaro, & Walker, Frequency of Frequencies Distributions and
Size Dependent Exchangeable Random Partitions
</a>
</li>

<li> <a href="https://mingyuanzhou.github.io/Papers/AISTATS2012_NegBinoBeta_PFA_v19.pdf">Zhou, Hannah, Dunson, & Carin, Beta-Negative Binomial Process and Poisson Factor Analysis
</a>
</li>


<li> <a href="https://mingyuanzhou.github.io/Papers/Mingyuan_PAMI_9.pdf">Zhou & Carin, Negative Binomial Process Count and Mixture Modeling
</a>
</li>

<li> <a href="http://mingyuanzhou.github.io/Papers/NBP_VectorMatrix_Journal_revise3_ArXiv.pdf">Zhou & Scott, Priors for Random Count Matrices Derived from a
Family of Negative Binomial Processes
</a>
</li>

<li> <a href="http://mingyuanzhou.github.io/Papers/BNBP_Collapsed_v7_arXiv.pdf">M. Zhou, Beta-Negative Binomial Process and Exchangeable Random Partitions for Mixed-Membership Modeling
</a>
</li>


<li> <a href="http://mingyuanzhou.github.io/Papers/EPM_AISTATS2015_v8_1.pdf">M. Zhou, Infinite Edge Partition Models for Overlapping
Community Detection and Link Prediction</a>
</li>

	</ul>

</li>



<li> Lecture 12: Bayesian Deep Learning
	<ul>
	
<li> <a href="http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf">Hinton, Osindero, & Teh, A Fast Learning Algorithm for Deep Belief Nets
</a>
</li> 

<li> <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">LeCun, Bengio, & Hinton, Deep Learning
</a>
</li> 

<li> <a href="http://www.cs.toronto.edu/~hinton/absps/tics.pdf">G. Hinton, Learning multiple layers of
representation
</a>
</li> 



<li> <a href="http://jmlr.org/papers/volume17/15-633/15-633.pdf">Zhou, Cong, & Chen, Augmentable Gamma Belief Networks
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1312.6114">Kingma & Welling, Auto-Encoding Variational Bayes
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1401.4082">Rezende, Mohamed, & Wierstra, Stochastic Backpropagation and Approximate Inference in Deep Generative Models. 
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1509.00519">Burda, Grosse, & Salakhutdinov, Importance Weighted Autoencoders
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1505.05770">Rezende & Mohamed, Variational Inference with Normalizing Flows
</a>
</li> 

<li> <a href="https://www.cs.toronto.edu/~amnih/papers/nvil.pdf"> Mnih & Gregor, Neural Variational Inference and Learning in Belief Networks
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1611.00712"> Maddison, Mnih, & Teh, The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1611.01144"> Jang, Gu, & Pool, Categorical Reparameterization with Gumbel-Softmax
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1406.2661">Goodfellow et al., Generative Adversarial Nets
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1701.00160">I. Goodfellow, Nips 2016 Tutorial: Generative Adversarial Networks
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1605.09782">Donahue, Krähenbühl, & Darrell, Adversarial Feature Learning
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1606.00704">Dumoulin et al., Adversarially Learned Inference
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1610.03483">Mohamed & Lakshminarayanan, Learning in Implicit Generative Models
</a>
</li> 

<li> <a href="https://arxiv.org/abs/1702.08896">Tran, Ranganath, & Blei, Hierarchical Implicit Models and Likelihood-Free Variational Inference
</a>
</li> 






	</ul>

</li>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/mingyuanzhou">mingyuanzhou</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
